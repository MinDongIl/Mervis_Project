[연구 일지] 2026-02-02

1. 주요 내용
크롤러의 동시성 문제 해결을 통한 데이터 수집 안정화 및 '수집-채점-학습-실전'이 순환하는 완전 자동화 서버 파이프라인(Server Pipeline) 구축.

2. 진행 요약
기존 크롤러(mervis_crawler.py) 구동 시 발생한 API 토큰 중복 발급 문제와 중요 학습 데이터(Price) 누락 문제를 코드로 수정하여 데이터 정합성을 확보함. 이후 24시간 무중단 서버 운영을 위해 단일 작업 방식에서 탈피, mervis_server_manager.py를 중심으로 한 스케줄링 시스템을 도입함. 특히 단순 수집을 넘어 AI가 스스로 정답을 채점(Labeler)하고 모델을 재학습(Trainer)하는 선순환 구조를 구현하였으며, 기존 ARIMA(시계열) 모델을 수급과 펀더멘털을 모두 반영할 수 있는 Boosted Tree(회귀) 모델로 고도화함.

3. 주요 수정 및 개발 내용
데이터 수집 안정화 (Crawler Stabilization):
Race Condition 해결: 멀티 스레드 진입 전 메인 스레드에서 토큰을 사전 발급하도록 로직을 변경하여, 10개 스레드의 동시 토큰 요청으로 인한 API 오류 차단.

스키마 보정: 학습에 필수적인 price 데이터가 BigQuery에 적재되지 않던 문제를 수정하고, 테이블 스키마 자동 보정(ensure_schema) 로직 적용.

서버 자동화 및 ML 파이프라인 구축 (Automation & ML Pipeline):
Server Manager (mervis_server_manager.py): schedule 라이브러리와 subprocess를 활용하여 07:00부터 '수집 → 채점 → 학습 → 복기'가 순차적으로 실행되는 파이프라인 구현.
Auto Learning (mervis_auto.py): GUI 의존성을 제거한 헤드리스(Headless) 모드로, 장 운영 시간 동안 실시간 데이터를 학습하고 신호를 포착하는 데몬 프로세스 개발.

Labeler & Trainer:
mervis_labeler.py: SQL LEAD() 함수를 이용해 과거 데이터의 수익률(next_day_return)을 자동 계산하여 정답지 생성.
mervis_trainer.py: 정답지가 확보된 데이터를 기반으로 BOOSTED_TREE_REGRESSOR 모델을 매일 아침 재학습시키는 로직 구현.

4. 시행 착오 및 오류 해결
[API 토큰 레이스 컨디션]
증상: 크롤러 실행 시 카카오톡 알림이 9개 이상 폭주하며 증권사 서버 부하 유발 우려.
원인: ThreadPoolExecutor 내부에서 각 워커가 경쟁적으로 토큰 발급을 시도함.
해결: 반복문 진입 전 1회 동기 호출로 토큰을 생성 및 파일화하여 중복 요청 원천 차단.

[스케줄링 프로세스 관리]
고민: 크롤링 소요 시간이 유동적(15분~1시간)이라 고정 시간표 방식은 비효율적임.
해결: 시간 기반 실행이 아닌, 앞 단계 프로세스가 정상 종료(Exit Code 0)되어야 다음 단계가 실행되는 '체인(Chain)' 방식의 함수형 로직으로 변경.

[학습 모델의 한계]
문제: 기존 ARIMA 모델은 가격 흐름만 볼 뿐, 수집된 수급/재무 데이터를 활용하지 못함.
해결: 다양한 Feature(PER, 수급, RSI 등)를 모두 학습할 수 있는 XGBoost 기반의 BOOSTED_TREE_REGRESSOR로 모델 교체 및 쿼리 수정.

5. 다음 목표
데이터 정합성 검증: 내일 아침(07:00 이후) 로그 및 BigQuery를 확인하여 파이프라인(수집-라벨링-학습)이 에러 없이 완주했는지 검증.
GUI 시각화 연동: 로컬 main_gui.py를 수정하여 서버가 적재한 학습 결과와 추천 종목을 시각적으로 표출.
Docker 컨테이너화: 검증 완료된 현재 환경을 Docker Image로 빌드하여 배포 환경 표준화 시작.