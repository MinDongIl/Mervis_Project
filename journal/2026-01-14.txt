[연구 일지] 2026-01-14

1. 주요 내용
안정적인 24시간 자동매매를 위한 클라우드(GCP Linux) 이관 계획 수립 및 빅쿼리 ML 모델 학습을 위한 데이터 파이프라인(Schema & Ingestion) 무결성 확보.

2. 진행 요약
로컬 PC 환경의 한계(전원, 네트워크 불안정)를 극복하기 위해 클라우드 서버 도입을 검토하던 중, Windows Server의 고비용 문제를 발견하고 비용 효율적인 Linux(Ubuntu) 환경으로의 전환을 확정함. 또한, 빅쿼리 ML 모델 생성 과정에서 학습 데이터(daily_features)에 핵심 변수인 '가격(Price)' 정보가 누락되어 수익률 라벨링이 불가능했던 치명적인 결함을 발견함. 이를 해결하기 위해 DB 스키마 수정, 크롤러 로직 개선, 그리고 실전 매매(Inference) 연결까지 포함된 '클라우드 이주 및 고도화 5단계 로드맵'을 수립함.

3. 주요 수정 및 개발 내용
빅쿼리 데이터 파이프라인 수정:
머신러닝 모델이 '내일의 수익률'을 계산하기 위해서는 과거 시점의 '가격'이 필수적임을 확인.
daily_features 테이블 스키마에 price 컬럼 추가 및 mervis_bigquery.py의 적재 로직(save_daily_features)에 가격 저장 코드 구현.

ML 예측-매매 로직 연결 (Inference):
빅쿼리의 예측값(Forecast)을 파이썬으로 가져오는 get_prediction 함수 신규 작성.
brain.py 분석 리포트 프롬프트에 AI 예측값(예상 수익률, 신뢰 구간)을 포함시켜, LLM이 기술적/기본적 분석과 더불어 머신러닝 예측까지 종합 판단하도록 개선.

클라우드 이관 로드맵 수립:
서버 구축(Ubuntu) -> 환경 설정 -> 코드/키 이관 -> 데이터 재수집(Re-crawl) -> ML 모델 생성으로 이어지는 단계별 계획 확정.

4. 시행 착오 및 오류 해결
[클라우드 비용 및 환경 이슈]
고민: 24시간 가동을 위해 Windows Server 인스턴스를 구성했으나, 라이선스 비용 포함 월 10만 원대(70달러 이상)의 과도한 유지비가 예상됨.
해결: GUI의 편리함보다는 '비용 효율성'과 '자동화'가 우선임을 재확인. 무료 등급(Free Tier) 활용이 가능하거나 월 1~2만 원대로 운용 가능한 Ubuntu(Linux) + CLI 환경으로 전환 결정.

[ML 모델 학습 데이터 공백]
증상: CREATE MODEL 쿼리 실행 시 "Input data doesn't contain any rows" 오류 발생.
원인: 크롤러가 보조지표(RSI 등)만 저장하고 정작 '얼마인지(Price)'를 저장하지 않아, 빅쿼리가 next_day_return(수익률)을 계산할 수 없었음. (Labeling 불가)
해결: 크롤링 코드에 price 저장 로직을 추가하고, 기존 데이터로는 학습이 불가능함을 인정하여 서버 구축 후 전수 재수집(Backfill)하기로 결정.

[뇌(ML)와 몸통(매매)의 분리 확인]
분석: 코드를 점검한 결과, ML 모델을 만드는 쿼리만 있고 정작 매매 판단 시에는 그 예측값을 참조하는 코드가 전무했음.
해결: brain.py가 빅쿼리 모델에게 직접 질의(Query)하여 예측값을 받아오도록 파이프라인을 연결함.

5. 다음 목표
Linux 서버 구축 및 환경 세팅: GCP에서 Ubuntu 인스턴스 생성 및 Python, Timezone, Git 환경 설정.
코드 배포 및 무중단 크롤링 시작: 수정된 크롤러를 서버에 배포하고 nohup으로 24시간 가동하여 학습용 데이터(Price 포함) 확보.
ML 모델 생성: 데이터가 충분히 쌓인 후(익일 오전), 빅쿼리에서 ARIMA 모델 학습 쿼리 실행 및 정상 동작 확인.